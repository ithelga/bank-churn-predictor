{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsxo54W7EOfDShnm7BaTHK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ithelga/bank-churn-predictor/blob/main/notebooks/Team2_HW5_Final_Train_Pipeline_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvhDkeYBJEMp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import joblib\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "bpIyJBg4JPmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_gKDSSDJLhX",
        "outputId": "e4bc866e-f37d-4906-c45e-e7e049026e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'drive/MyDrive/Colab Notebooks/Bank churn predictor/data'\n",
        "row_df = pd.read_csv(f'{data_path}/row_dataset.csv')"
      ],
      "metadata": {
        "id": "wOwC4WZZJNGW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "        self.num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance',\n",
        "                         'NumOfProducts', 'EstimatedSalary']\n",
        "        self.cat_cols = ['Geography']\n",
        "\n",
        "    def _clean_data(self, X):\n",
        "        df = X.copy()\n",
        "\n",
        "        # Удалим неинформативные столбцы\n",
        "        df = df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], errors='ignore')\n",
        "\n",
        "        # Заполнение пропусков\n",
        "        df['Geography'] = df['Geography'].fillna(df['Geography'].mode()[0])\n",
        "        df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "\n",
        "        # Удалим остальные пропуски и дубликаты\n",
        "        df = df.dropna()\n",
        "        df = df.drop_duplicates()\n",
        "\n",
        "        # Gender в 0/1\n",
        "        df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})\n",
        "\n",
        "        return df\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        df = self._clean_data(X)\n",
        "\n",
        "        # Обучаем scaler и OHE\n",
        "        self.scaler.fit(df[self.num_cols])\n",
        "        self.ohe.fit(df[self.cat_cols])\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        df = self._clean_data(X)\n",
        "\n",
        "        # One-hot encoding для Geography\n",
        "        geo_encoded = self.ohe.transform(df[self.cat_cols])\n",
        "        geo_df = pd.DataFrame(\n",
        "            geo_encoded,\n",
        "            columns=self.ohe.get_feature_names_out(self.cat_cols),\n",
        "            index=df.index\n",
        "        )\n",
        "\n",
        "        # Масштабирование числовых\n",
        "        df_scaled = self.scaler.transform(df[self.num_cols])\n",
        "        df_scaled = pd.DataFrame(df_scaled, columns=self.num_cols, index=df.index)\n",
        "\n",
        "        # Итоговый датафрейм\n",
        "        final_df = pd.concat([df_scaled, geo_df, df['Gender']], axis=1)\n",
        "\n",
        "        return final_df"
      ],
      "metadata": {
        "id": "UnvhqMdCOJTN"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_export_model(row_df, save_dir):\n",
        "    import os\n",
        "    import joblib\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Разделяем данные\n",
        "    target = row_df['Exited']\n",
        "    features = row_df.drop(columns=['Exited'])\n",
        "\n",
        "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "        features, target, test_size=0.25, stratify=target, random_state=42\n",
        "    )\n",
        "\n",
        "    # Предобработка\n",
        "    preprocessor = Preprocessor()\n",
        "    X_clean = preprocessor._clean_data(X_train_raw)\n",
        "    y_clean = y_train.loc[X_clean.index]\n",
        "\n",
        "    preprocessor.fit(X_train_raw)\n",
        "    X_train_proc = preprocessor.transform(X_train_raw)\n",
        "    X_train_proc = X_train_proc.loc[y_clean.index]\n",
        "\n",
        "    # Модель с уже известными лучшими параметрами\n",
        "    model = RandomForestClassifier(\n",
        "        class_weight='balanced',\n",
        "        n_estimators=200,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=5,\n",
        "        max_features='sqrt',\n",
        "        max_depth=None,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_proc, y_clean)\n",
        "\n",
        "    # Сохраняем\n",
        "    joblib.dump(preprocessor, os.path.join(save_dir, \"preprocessor.pkl\"))\n",
        "    joblib.dump(model, os.path.join(save_dir, \"random_forest_model.pkl\"))\n",
        "    X_test_raw.assign(Exited=y_test.values).to_csv(os.path.join(save_dir, \"test_raw.csv\"), index=False)\n",
        "\n",
        "    print(\"Модель, препроцессор и тестовые данные сохранены.\")"
      ],
      "metadata": {
        "id": "XzqGqMBYTI6e"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_export_model(row_df, save_dir='drive/MyDrive/Colab Notebooks/Bank churn predictor/final_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7CQjSTSRy7r",
        "outputId": "752b2c76-b17a-48da-aae9-24f3ad703455"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель, препроцессор и тестовые данные сохранены.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "def train_and_evaluate(row_df):\n",
        "    target = row_df['Exited']\n",
        "    features = row_df.drop(columns=['Exited'])\n",
        "\n",
        "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "        features, target, test_size=0.25, stratify=target, random_state=42\n",
        "    )\n",
        "\n",
        "    # Logistic Regression (baseline)\n",
        "    lr_model = LogisticRegression(\n",
        "        class_weight='balanced',\n",
        "        max_iter=500,\n",
        "        solver='lbfgs',\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Только числовые колонки + заполнение NaN\n",
        "    X_train_lr = X_train_raw.select_dtypes(include='number').copy()\n",
        "    X_test_lr = X_test_raw.select_dtypes(include='number').copy()\n",
        "\n",
        "    # Заполнение пропусков медианой\n",
        "    X_train_lr = X_train_lr.fillna(X_train_lr.median())\n",
        "    X_test_lr = X_test_lr.fillna(X_train_lr.median())\n",
        "\n",
        "    lr_model.fit(X_train_lr, y_train)\n",
        "    y_pred_lr = lr_model.predict(X_test_lr)\n",
        "    y_proba_lr = lr_model.predict_proba(X_test_lr)[:, 1]\n",
        "\n",
        "    print(\"Logistic Regression (первоначальные данные):\")\n",
        "    print(f\"F1: {f1_score(y_test, y_pred_lr):.3f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred_lr):.3f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred_lr):.3f}\")\n",
        "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba_lr):.3f}\")\n",
        "    print()\n",
        "\n",
        "    #  Random Forest (предобработка)\n",
        "    preprocessor = Preprocessor()\n",
        "\n",
        "    X_train_clean = preprocessor._clean_data(X_train_raw)\n",
        "    y_train_clean = y_train.loc[X_train_clean.index]\n",
        "    preprocessor.fit(X_train_clean)\n",
        "    X_train_proc = preprocessor.transform(X_train_clean)\n",
        "\n",
        "    X_test_clean = preprocessor._clean_data(X_test_raw)\n",
        "    y_test_clean = y_test.loc[X_test_clean.index]\n",
        "    X_test_proc = preprocessor.transform(X_test_clean)\n",
        "\n",
        "    model = RandomForestClassifier(\n",
        "        class_weight='balanced',\n",
        "        n_estimators=200,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=5,\n",
        "        max_features='sqrt',\n",
        "        max_depth=None,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    model.fit(X_train_proc, y_train_clean)\n",
        "\n",
        "    y_pred_rf = model.predict(X_test_proc)\n",
        "    y_proba_rf = model.predict_proba(X_test_proc)[:, 1]\n",
        "\n",
        "    print(\"RandomForest (на предобработанных данных):\")\n",
        "    print(f\"F1: {f1_score(y_test_clean, y_pred_rf):.3f}\")\n",
        "    print(f\"Precision: {precision_score(y_test_clean, y_pred_rf):.3f}\")\n",
        "    print(f\"Recall: {recall_score(y_test_clean, y_pred_rf):.3f}\")\n",
        "    print(f\"ROC-AUC: {roc_auc_score(y_test_clean, y_proba_rf):.3f}\")"
      ],
      "metadata": {
        "id": "sDJLRpIEZo4M"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate(row_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPv5Ikr5ZqJ_",
        "outputId": "a2d86910-bab6-45c2-96f9-5e3e9725a6cf"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (первоначальные данные):\n",
            "F1: 0.479\n",
            "Precision: 0.365\n",
            "Recall: 0.696\n",
            "ROC-AUC: 0.752\n",
            "\n",
            "RandomForest (на предобработанных данных):\n",
            "F1: 0.612\n",
            "Precision: 0.580\n",
            "Recall: 0.647\n",
            "ROC-AUC: 0.856\n"
          ]
        }
      ]
    }
  ]
}